{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizer Evaluation Notebook\n",
    "\n",
    "This notebook evaluates different summarization models on a subset of the training dataset.\n",
    "The evaluation metrics are Faithfulness, Relevance, Coherence, Conciseness, and Language Consistency,\n",
    "provided by a GPT-based `SummarizationJudge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dortenenboim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\repos\\search-summaries\\.venv\\Lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables (e.g., OPENAI_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "# Import summarizers\n",
    "from summarizers.light import FastSummarizer, SumyTextRankSummarizer, TFIDFSummarizer\n",
    "\n",
    "\n",
    "# Import the judge\n",
    "from judge import SummarizationJudge, SummarizationScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset/unified_dataset.csv'\n",
    "TEXT_COLUMN = 'text'\n",
    "LANGUAGE_COLUMN = 'language'\n",
    "MAX_SENTENCES_SUMMARY = 3\n",
    "N_SAMPLES = 10\n",
    "TARGET_LANGUAGES = ['english', 'german', 'arabic', 'chinese', 'spanish', 'french']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully. Shape: (202, 7)\n",
      "Available languages: ['english' 'spanish' 'french' 'german' 'chinese' 'arabic']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_full = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Dataset loaded successfully. Shape: {df_full.shape}\")\n",
    "    print(f\"Available languages: {df_full[LANGUAGE_COLUMN].unique()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Dataset file not found at {DATASET_PATH}\")\n",
    "    df_full = pd.DataFrame() # Create empty df to avoid further errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Data\n",
    "\n",
    "We need to select `N_SAMPLES` (20) from the dataset, ensuring at least one sample from each of the `TARGET_LANGUAGES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target languages available in dataset: ['english', 'german', 'arabic', 'chinese', 'spanish', 'french']\n",
      "Selected 10 samples for evaluation.\n",
      "Language distribution in selected samples:\n",
      "language\n",
      "english    3\n",
      "german     2\n",
      "spanish    2\n",
      "arabic     1\n",
      "chinese    1\n",
      "french     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure all target languages are present in the dataset\n",
    "available_target_languages = [lang for lang in TARGET_LANGUAGES if lang in df_full[LANGUAGE_COLUMN].unique()]\n",
    "print(f\"Target languages available in dataset: {available_target_languages}\")\n",
    "\n",
    "sampled_dfs = []\n",
    "# Get at least one sample from each available target language\n",
    "for lang in available_target_languages:\n",
    "    lang_sample = df_full[df_full[LANGUAGE_COLUMN] == lang].sample(n=1, random_state=42)\n",
    "    sampled_dfs.append(lang_sample)\n",
    "\n",
    "df_sampled_langs = pd.concat(sampled_dfs)\n",
    "\n",
    "remaining_samples_needed = N_SAMPLES - len(df_sampled_langs)\n",
    "\n",
    "if remaining_samples_needed > 0:\n",
    "    # Get remaining samples from the rest of the dataset, excluding already sampled rows\n",
    "    df_remaining_pool = df_full.drop(df_sampled_langs.index)\n",
    "    if len(df_remaining_pool) >= remaining_samples_needed:\n",
    "        df_additional_samples = df_remaining_pool.sample(n=remaining_samples_needed, random_state=42)\n",
    "        df_eval = pd.concat([df_sampled_langs, df_additional_samples])\n",
    "    else:\n",
    "        # If not enough unique samples left, take all available\n",
    "        df_eval = pd.concat([df_sampled_langs, df_remaining_pool])\n",
    "        print(f\"Warning: Could only sample {len(df_eval)} rows due to data constraints.\")\n",
    "elif N_SAMPLES < len(df_sampled_langs): # If we sampled more than N_SAMPLES because we have many target_languages\n",
    "    df_eval = df_sampled_langs.sample(n=N_SAMPLES, random_state=42)\n",
    "else: # Exactly N_SAMPLES were sampled, or N_SAMPLES == len(available_target_languages)\n",
    "    df_eval = df_sampled_langs\n",
    "\n",
    "print(f\"Selected {len(df_eval)} samples for evaluation.\")\n",
    "print(\"Language distribution in selected samples:\")\n",
    "print(df_eval[LANGUAGE_COLUMN].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Summarizers and Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSummarizer initialized.\n",
      "SummarizationJudge initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize summarizers\n",
    "fast_summarizer = FastSummarizer()\n",
    "print(\"HybridSummarizer initialized.\")\n",
    "\n",
    "sumy_summarizer = SumyTextRankSummarizer()\n",
    "\n",
    "tf_idf_summarizer = TFIDFSummarizer()\n",
    "summarizers = {\n",
    "    \"fast\": fast_summarizer,\n",
    "    \"summy\": sumy_summarizer,\n",
    "    \"tf-idf\": tf_idf_summarizer,\n",
    "}\n",
    "\n",
    "# Initialize the judge\n",
    "# Assumes OPENAI_API_KEY is in .env or environment variables\n",
    "try:\n",
    "    judge = SummarizationJudge()\n",
    "    print(\"SummarizationJudge initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SummarizationJudge: {e}. Make sure OPENAI_API_KEY is set.\")\n",
    "    judge = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Loop\n",
    "\n",
    "Iterate through each row in the sampled dataset, apply each summarizer, and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sample from row 40 (Language: english)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.2677 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=3, R=4, C=4, Con=4, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0893 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0103 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=1, R=1, C=1, Con=1, LC=True\n",
      "\n",
      "Processing sample from row 149 (Language: german)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.1789 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0456 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0090 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=1, R=1, C=1, Con=1, LC=True\n",
      "\n",
      "Processing sample from row 200 (Language: arabic)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.1563 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=3, R=3, C=2, Con=2, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0308 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=3, R=3, C=3, Con=2, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0084 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=3, R=3, C=3, Con=3, LC=True\n",
      "\n",
      "Processing sample from row 168 (Language: chinese)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.0224 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0072 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0020 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=4, R=4, C=4, Con=4, LC=True\n",
      "\n",
      "Processing sample from row 118 (Language: spanish)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.0530 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0150 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=3, R=4, C=4, Con=4, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0030 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=1, R=1, C=2, Con=2, LC=True\n",
      "\n",
      "Processing sample from row 120 (Language: french)...\n",
      "  Applying fast...\n",
      "    fast latency: 1.0008 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=3, R=3, C=3, Con=3, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.1910 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=3, R=3, C=3, Con=3, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0157 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=2, R=2, C=3, Con=4, LC=True\n",
      "\n",
      "Processing sample from row 142 (Language: german)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.0889 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=3, R=3, C=4, Con=3, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0338 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=3, R=3, C=3, Con=3, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0041 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=3, R=3, C=3, Con=3, LC=True\n",
      "\n",
      "Processing sample from row 114 (Language: spanish)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.3340 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=3, R=3, C=3, Con=3, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0751 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0153 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=1, R=1, C=1, Con=1, LC=True\n",
      "\n",
      "Processing sample from row 16 (Language: english)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.3285 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=4, R=4, C=4, Con=4, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0649 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=3, R=2, C=2, Con=2, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0222 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=2, R=2, C=3, Con=2, LC=True\n",
      "\n",
      "Processing sample from row 76 (Language: english)...\n",
      "  Applying fast...\n",
      "    fast latency: 0.0847 seconds\n",
      "    Evaluating fast summary...\n",
      "    Scores for fast: F=3, R=3, C=3, Con=3, LC=True\n",
      "  Applying summy...\n",
      "    summy latency: 0.0454 seconds\n",
      "    Evaluating summy summary...\n",
      "    Scores for summy: F=2, R=2, C=2, Con=3, LC=True\n",
      "  Applying tf-idf...\n",
      "    tf-idf latency: 0.0050 seconds\n",
      "    Evaluating tf-idf summary...\n",
      "    Scores for tf-idf: F=2, R=2, C=2, Con=3, LC=True\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "\n",
    "if not df_eval.empty and judge:\n",
    "    \n",
    "    for index, row in df_eval.iterrows():\n",
    "        original_text = str(row[TEXT_COLUMN])\n",
    "        language = str(row[LANGUAGE_COLUMN])\n",
    "        \n",
    "        print(f\"\\nProcessing sample from row {row.name} (Language: {language})...\") # Using row.name for original index\n",
    "\n",
    "        if not original_text.strip():\n",
    "            print(f\"Skipping sample from row {row.name} due to empty original text.\")\n",
    "            continue\n",
    "\n",
    "        for summarizer_name, summarizer_instance in summarizers.items():\n",
    "            print(f\"  Applying {summarizer_name}...\")\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                # Ensure the summarizer's summarize method matches expected signature\n",
    "                if hasattr(summarizer_instance, 'summarize'):\n",
    "                    summary = summarizer_instance.summarize(\n",
    "                        text=original_text, \n",
    "                        language=language, \n",
    "                        max_sentences=MAX_SENTENCES_SUMMARY\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"    Error: {summarizer_name} does not have a 'summarize' method or signature mismatch.\")\n",
    "                    summary = \"Error: Summarizer method issue.\"\n",
    "                \n",
    "                end_time = time.time()\n",
    "                latency_seconds = end_time - start_time\n",
    "                print(f\"    {summarizer_name} latency: {latency_seconds:.4f} seconds\")\n",
    "\n",
    "                if not summary.strip():\n",
    "                    print(f\"    {summarizer_name} produced an empty summary.\")\n",
    "                    scores = SummarizationScore(faithfulness=1, relevance=1, coherence=1, conciseness=1, language_consistency=0) \n",
    "                else:\n",
    "                    print(f\"    Evaluating {summarizer_name} summary...\")\n",
    "                    scores = judge.evaluate_summary(\n",
    "                        original_markdown=original_text,\n",
    "                        summary=summary,\n",
    "                        language=language\n",
    "                    )\n",
    "                \n",
    "                results.append({\n",
    "                    \"sample_original_index\": row.name, # Store original index\n",
    "                    \"url\": row['url'],\n",
    "                    \"language\": language,\n",
    "                    \"summarizer\": summarizer_name,\n",
    "                    \"original_text_preview\": original_text[:100] + \"...\", \n",
    "                    \"original_text_length\": len(original_text),\n",
    "                    \"summary\": summary,\n",
    "                    \"summary_length\": len(summary),\n",
    "                    \"faithfulness\": scores.faithfulness,\n",
    "                    \"relevance\": scores.relevance,\n",
    "                    \"coherence\": scores.coherence,\n",
    "                    \"conciseness\": scores.conciseness,\n",
    "                    \"language_consistency\": int(scores.language_consistency),\n",
    "                    \"latency_seconds\": latency_seconds\n",
    "                })\n",
    "                print(f\"    Scores for {summarizer_name}: F={scores.faithfulness}, R={scores.relevance}, C={scores.coherence}, Con={scores.conciseness}, LC={scores.language_consistency}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Error during summarization or evaluation with {summarizer_name} for sample {row.name}: {e}\")\n",
    "                results.append({\n",
    "                    \"sample_original_index\": row.name,\n",
    "                    \"language\": language,\n",
    "                    \"summarizer\": summarizer_name,\n",
    "                    \"original_text_preview\": original_text[:100] + \"...\",\n",
    "                    \"original_text_length\": len(original_text),\n",
    "                    \"summary\": f\"Error: {e}\",\n",
    "                    \"faithfulness\": 0,\n",
    "                    \"relevance\": 0,\n",
    "                    \"coherence\": 0,\n",
    "                    \"conciseness\": 0,\n",
    "                    \"language_consistency\": 0,\n",
    "                    \"latency_seconds\": -1\n",
    "                })\n",
    "else:\n",
    "    print(\"Skipping evaluation loop due to empty dataset or uninitialized judge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_original_index</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>summarizer</th>\n",
       "      <th>original_text_preview</th>\n",
       "      <th>original_text_length</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>conciseness</th>\n",
       "      <th>language_consistency</th>\n",
       "      <th>latency_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>https://www.bbc.com/news/business-57253947</td>\n",
       "      <td>english</td>\n",
       "      <td>fast</td>\n",
       "      <td>Why electric cars will take over sooner than y...</td>\n",
       "      <td>10217</td>\n",
       "      <td>Keywords : [electric cars, new electric car, T...</td>\n",
       "      <td>1048</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>https://www.bbc.com/news/business-57253947</td>\n",
       "      <td>english</td>\n",
       "      <td>summy</td>\n",
       "      <td>Why electric cars will take over sooner than y...</td>\n",
       "      <td>10217</td>\n",
       "      <td>But the sea-change in performance Mr Willson h...</td>\n",
       "      <td>584</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>https://www.bbc.com/news/business-57253947</td>\n",
       "      <td>english</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Why electric cars will take over sooner than y...</td>\n",
       "      <td>10217</td>\n",
       "      <td>So did steam engines and printing presses. \"It...</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>https://www.sueddeutsche.de/politik/cybersiche...</td>\n",
       "      <td>german</td>\n",
       "      <td>fast</td>\n",
       "      <td>Cybersicherheit: Im Visier von Staatshackern u...</td>\n",
       "      <td>7919</td>\n",
       "      <td>Keywords : [über das die Angreifer, Die Gruppe...</td>\n",
       "      <td>764</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>https://www.sueddeutsche.de/politik/cybersiche...</td>\n",
       "      <td>german</td>\n",
       "      <td>summy</td>\n",
       "      <td>Cybersicherheit: Im Visier von Staatshackern u...</td>\n",
       "      <td>7919</td>\n",
       "      <td>Jetzt wollen FBI und Co. es zumindest geschaff...</td>\n",
       "      <td>794</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149</td>\n",
       "      <td>https://www.sueddeutsche.de/politik/cybersiche...</td>\n",
       "      <td>german</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Cybersicherheit: Im Visier von Staatshackern u...</td>\n",
       "      <td>7919</td>\n",
       "      <td>So dramatisch es klingen mag: praktisch jeder....</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>https://www.alarabiya.net/technology/ai</td>\n",
       "      <td>arabic</td>\n",
       "      <td>fast</td>\n",
       "      <td>أهم وآخر أخبار الذكاء الاصطناعي| العربية\\n.\\n....</td>\n",
       "      <td>5826</td>\n",
       "      <td>Keywords : [الاصطناعي منذ, الاصطناعي محل قلقال...</td>\n",
       "      <td>1329</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>https://www.alarabiya.net/technology/ai</td>\n",
       "      <td>arabic</td>\n",
       "      <td>summy</td>\n",
       "      <td>أهم وآخر أخبار الذكاء الاصطناعي| العربية\\n.\\n....</td>\n",
       "      <td>5826</td>\n",
       "      <td>السبت 21 شوال 1446 هـ - 19 أبريل 2025 الحدث en...</td>\n",
       "      <td>5628</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>https://www.alarabiya.net/technology/ai</td>\n",
       "      <td>arabic</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>أهم وآخر أخبار الذكاء الاصطناعي| العربية\\n.\\n....</td>\n",
       "      <td>5826</td>\n",
       "      <td>السبت 21 شوال 1446 هـ - 19 أبريل 2025 الحدث en...</td>\n",
       "      <td>4215</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>168</td>\n",
       "      <td>http://www.xinhuanet.com/talking/20240904/0599...</td>\n",
       "      <td>chinese</td>\n",
       "      <td>fast</td>\n",
       "      <td>新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级\\n\\n新潮澎湃看中国｜技术创新引领新能源...</td>\n",
       "      <td>1097</td>\n",
       "      <td>Keywords : [近四十年深耕 见证新能源汽车从无到有, 新潮澎湃看中国｜技术创新引领...</td>\n",
       "      <td>1162</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>168</td>\n",
       "      <td>http://www.xinhuanet.com/talking/20240904/0599...</td>\n",
       "      <td>chinese</td>\n",
       "      <td>summy</td>\n",
       "      <td>新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级\\n\\n新潮澎湃看中国｜技术创新引领新能源...</td>\n",
       "      <td>1097</td>\n",
       "      <td>新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级 新潮澎湃看中国｜技术创新引领新能源汽车产...</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168</td>\n",
       "      <td>http://www.xinhuanet.com/talking/20240904/0599...</td>\n",
       "      <td>chinese</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级\\n\\n新潮澎湃看中国｜技术创新引领新能源...</td>\n",
       "      <td>1097</td>\n",
       "      <td>新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级 新潮澎湃看中国｜技术创新引领新能源汽车产...</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>118</td>\n",
       "      <td>https://ecab-estadistica.medium.com/ciencia-de...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>fast</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nMember-o...</td>\n",
       "      <td>1635</td>\n",
       "      <td>Keywords : [jefe de la, los gobiernos y los in...</td>\n",
       "      <td>1334</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>118</td>\n",
       "      <td>https://ecab-estadistica.medium.com/ciencia-de...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>summy</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nMember-o...</td>\n",
       "      <td>1635</td>\n",
       "      <td>Sign up Sign in Sign up Sign in Member-only st...</td>\n",
       "      <td>705</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>118</td>\n",
       "      <td>https://ecab-estadistica.medium.com/ciencia-de...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nMember-o...</td>\n",
       "      <td>1635</td>\n",
       "      <td>-- Written by Elisa Cabana PhD in Statistics, ...</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>120</td>\n",
       "      <td>https://www.lemonde.fr/energies-renouvelables/</td>\n",
       "      <td>french</td>\n",
       "      <td>fast</td>\n",
       "      <td>Consulter\\nle journal\\n\\nLéa Salamé, future pr...</td>\n",
       "      <td>25512</td>\n",
       "      <td>Keywords : [de la, le paradoxe de la Chine, le...</td>\n",
       "      <td>1469</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>https://www.lemonde.fr/energies-renouvelables/</td>\n",
       "      <td>french</td>\n",
       "      <td>summy</td>\n",
       "      <td>Consulter\\nle journal\\n\\nLéa Salamé, future pr...</td>\n",
       "      <td>25512</td>\n",
       "      <td>Ce que les images révèlent Israël-Iran : retou...</td>\n",
       "      <td>1939</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>120</td>\n",
       "      <td>https://www.lemonde.fr/energies-renouvelables/</td>\n",
       "      <td>french</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Consulter\\nle journal\\n\\nLéa Salamé, future pr...</td>\n",
       "      <td>25512</td>\n",
       "      <td>Malgré l’avis défavorable de Bercy. Et le tabl...</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>142</td>\n",
       "      <td>https://www.spiegel.de/netzwelt/netzpolitik/ri...</td>\n",
       "      <td>german</td>\n",
       "      <td>fast</td>\n",
       "      <td>Künstliche Intelligenz: KI-Koryphäen von OpenA...</td>\n",
       "      <td>3409</td>\n",
       "      <td>Keywords : [KI, das Risiko der Auslöschung dur...</td>\n",
       "      <td>1052</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>142</td>\n",
       "      <td>https://www.spiegel.de/netzwelt/netzpolitik/ri...</td>\n",
       "      <td>german</td>\n",
       "      <td>summy</td>\n",
       "      <td>Künstliche Intelligenz: KI-Koryphäen von OpenA...</td>\n",
       "      <td>3409</td>\n",
       "      <td>Künstliche Intelligenz: KI-Koryphäen von OpenA...</td>\n",
       "      <td>1053</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>142</td>\n",
       "      <td>https://www.spiegel.de/netzwelt/netzpolitik/ri...</td>\n",
       "      <td>german</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Künstliche Intelligenz: KI-Koryphäen von OpenA...</td>\n",
       "      <td>3409</td>\n",
       "      <td>Unterschrieben von denen, die KI selbst entwic...</td>\n",
       "      <td>558</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>114</td>\n",
       "      <td>https://medium.com/@noebranagan/https-medium-c...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>fast</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nHablemos...</td>\n",
       "      <td>12140</td>\n",
       "      <td>Keywords : [es un framework que, lo bueno de e...</td>\n",
       "      <td>1624</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>114</td>\n",
       "      <td>https://medium.com/@noebranagan/https-medium-c...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>summy</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nHablemos...</td>\n",
       "      <td>12140</td>\n",
       "      <td>Algo muy importante para mencionar es que Reac...</td>\n",
       "      <td>1459</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>114</td>\n",
       "      <td>https://medium.com/@noebranagan/https-medium-c...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nHablemos...</td>\n",
       "      <td>12140</td>\n",
       "      <td>Híbrido(Hybrid). Recomendaciones -- 1 Written ...</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>https://www.reuters.com/sustainability/climate...</td>\n",
       "      <td>english</td>\n",
       "      <td>fast</td>\n",
       "      <td>Published Time: 2025-05-22T15:01:12.702Z\\nHous...</td>\n",
       "      <td>11384</td>\n",
       "      <td>Keywords : [clean energy tax credits, clean en...</td>\n",
       "      <td>1361</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>https://www.reuters.com/sustainability/climate...</td>\n",
       "      <td>english</td>\n",
       "      <td>summy</td>\n",
       "      <td>Published Time: 2025-05-22T15:01:12.702Z\\nHous...</td>\n",
       "      <td>11384</td>\n",
       "      <td>Published Time: 2025-05-22T15:01:12.702Z Skip ...</td>\n",
       "      <td>3482</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>https://www.reuters.com/sustainability/climate...</td>\n",
       "      <td>english</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Published Time: 2025-05-22T15:01:12.702Z\\nHous...</td>\n",
       "      <td>11384</td>\n",
       "      <td>Sign up here. Read Next Sustainability categor...</td>\n",
       "      <td>1068</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>76</td>\n",
       "      <td>https://medium.com/codex/6-phases-of-data-anal...</td>\n",
       "      <td>english</td>\n",
       "      <td>fast</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nCodeX\\nF...</td>\n",
       "      <td>3582</td>\n",
       "      <td>Keywords : [Data processing, analysis, the con...</td>\n",
       "      <td>615</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>76</td>\n",
       "      <td>https://medium.com/codex/6-phases-of-data-anal...</td>\n",
       "      <td>english</td>\n",
       "      <td>summy</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nCodeX\\nF...</td>\n",
       "      <td>3582</td>\n",
       "      <td>In this post, I will explain the six data anal...</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>76</td>\n",
       "      <td>https://medium.com/codex/6-phases-of-data-anal...</td>\n",
       "      <td>english</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>Sign up\\nSign in\\nSign up\\nSign in\\n\\nCodeX\\nF...</td>\n",
       "      <td>3582</td>\n",
       "      <td>Keeping the line of communication with stakeho...</td>\n",
       "      <td>223</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_original_index                                                url  \\\n",
       "0                      40         https://www.bbc.com/news/business-57253947   \n",
       "1                      40         https://www.bbc.com/news/business-57253947   \n",
       "2                      40         https://www.bbc.com/news/business-57253947   \n",
       "3                     149  https://www.sueddeutsche.de/politik/cybersiche...   \n",
       "4                     149  https://www.sueddeutsche.de/politik/cybersiche...   \n",
       "5                     149  https://www.sueddeutsche.de/politik/cybersiche...   \n",
       "6                     200            https://www.alarabiya.net/technology/ai   \n",
       "7                     200            https://www.alarabiya.net/technology/ai   \n",
       "8                     200            https://www.alarabiya.net/technology/ai   \n",
       "9                     168  http://www.xinhuanet.com/talking/20240904/0599...   \n",
       "10                    168  http://www.xinhuanet.com/talking/20240904/0599...   \n",
       "11                    168  http://www.xinhuanet.com/talking/20240904/0599...   \n",
       "12                    118  https://ecab-estadistica.medium.com/ciencia-de...   \n",
       "13                    118  https://ecab-estadistica.medium.com/ciencia-de...   \n",
       "14                    118  https://ecab-estadistica.medium.com/ciencia-de...   \n",
       "15                    120     https://www.lemonde.fr/energies-renouvelables/   \n",
       "16                    120     https://www.lemonde.fr/energies-renouvelables/   \n",
       "17                    120     https://www.lemonde.fr/energies-renouvelables/   \n",
       "18                    142  https://www.spiegel.de/netzwelt/netzpolitik/ri...   \n",
       "19                    142  https://www.spiegel.de/netzwelt/netzpolitik/ri...   \n",
       "20                    142  https://www.spiegel.de/netzwelt/netzpolitik/ri...   \n",
       "21                    114  https://medium.com/@noebranagan/https-medium-c...   \n",
       "22                    114  https://medium.com/@noebranagan/https-medium-c...   \n",
       "23                    114  https://medium.com/@noebranagan/https-medium-c...   \n",
       "24                     16  https://www.reuters.com/sustainability/climate...   \n",
       "25                     16  https://www.reuters.com/sustainability/climate...   \n",
       "26                     16  https://www.reuters.com/sustainability/climate...   \n",
       "27                     76  https://medium.com/codex/6-phases-of-data-anal...   \n",
       "28                     76  https://medium.com/codex/6-phases-of-data-anal...   \n",
       "29                     76  https://medium.com/codex/6-phases-of-data-anal...   \n",
       "\n",
       "   language summarizer                              original_text_preview  \\\n",
       "0   english       fast  Why electric cars will take over sooner than y...   \n",
       "1   english      summy  Why electric cars will take over sooner than y...   \n",
       "2   english     tf-idf  Why electric cars will take over sooner than y...   \n",
       "3    german       fast  Cybersicherheit: Im Visier von Staatshackern u...   \n",
       "4    german      summy  Cybersicherheit: Im Visier von Staatshackern u...   \n",
       "5    german     tf-idf  Cybersicherheit: Im Visier von Staatshackern u...   \n",
       "6    arabic       fast  أهم وآخر أخبار الذكاء الاصطناعي| العربية\\n.\\n....   \n",
       "7    arabic      summy  أهم وآخر أخبار الذكاء الاصطناعي| العربية\\n.\\n....   \n",
       "8    arabic     tf-idf  أهم وآخر أخبار الذكاء الاصطناعي| العربية\\n.\\n....   \n",
       "9   chinese       fast  新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级\\n\\n新潮澎湃看中国｜技术创新引领新能源...   \n",
       "10  chinese      summy  新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级\\n\\n新潮澎湃看中国｜技术创新引领新能源...   \n",
       "11  chinese     tf-idf  新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级\\n\\n新潮澎湃看中国｜技术创新引领新能源...   \n",
       "12  spanish       fast  Sign up\\nSign in\\nSign up\\nSign in\\n\\nMember-o...   \n",
       "13  spanish      summy  Sign up\\nSign in\\nSign up\\nSign in\\n\\nMember-o...   \n",
       "14  spanish     tf-idf  Sign up\\nSign in\\nSign up\\nSign in\\n\\nMember-o...   \n",
       "15   french       fast  Consulter\\nle journal\\n\\nLéa Salamé, future pr...   \n",
       "16   french      summy  Consulter\\nle journal\\n\\nLéa Salamé, future pr...   \n",
       "17   french     tf-idf  Consulter\\nle journal\\n\\nLéa Salamé, future pr...   \n",
       "18   german       fast  Künstliche Intelligenz: KI-Koryphäen von OpenA...   \n",
       "19   german      summy  Künstliche Intelligenz: KI-Koryphäen von OpenA...   \n",
       "20   german     tf-idf  Künstliche Intelligenz: KI-Koryphäen von OpenA...   \n",
       "21  spanish       fast  Sign up\\nSign in\\nSign up\\nSign in\\n\\nHablemos...   \n",
       "22  spanish      summy  Sign up\\nSign in\\nSign up\\nSign in\\n\\nHablemos...   \n",
       "23  spanish     tf-idf  Sign up\\nSign in\\nSign up\\nSign in\\n\\nHablemos...   \n",
       "24  english       fast  Published Time: 2025-05-22T15:01:12.702Z\\nHous...   \n",
       "25  english      summy  Published Time: 2025-05-22T15:01:12.702Z\\nHous...   \n",
       "26  english     tf-idf  Published Time: 2025-05-22T15:01:12.702Z\\nHous...   \n",
       "27  english       fast  Sign up\\nSign in\\nSign up\\nSign in\\n\\nCodeX\\nF...   \n",
       "28  english      summy  Sign up\\nSign in\\nSign up\\nSign in\\n\\nCodeX\\nF...   \n",
       "29  english     tf-idf  Sign up\\nSign in\\nSign up\\nSign in\\n\\nCodeX\\nF...   \n",
       "\n",
       "    original_text_length                                            summary  \\\n",
       "0                  10217  Keywords : [electric cars, new electric car, T...   \n",
       "1                  10217  But the sea-change in performance Mr Willson h...   \n",
       "2                  10217  So did steam engines and printing presses. \"It...   \n",
       "3                   7919  Keywords : [über das die Angreifer, Die Gruppe...   \n",
       "4                   7919  Jetzt wollen FBI und Co. es zumindest geschaff...   \n",
       "5                   7919  So dramatisch es klingen mag: praktisch jeder....   \n",
       "6                   5826  Keywords : [الاصطناعي منذ, الاصطناعي محل قلقال...   \n",
       "7                   5826  السبت 21 شوال 1446 هـ - 19 أبريل 2025 الحدث en...   \n",
       "8                   5826  السبت 21 شوال 1446 هـ - 19 أبريل 2025 الحدث en...   \n",
       "9                   1097  Keywords : [近四十年深耕 见证新能源汽车从无到有, 新潮澎湃看中国｜技术创新引领...   \n",
       "10                  1097  新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级 新潮澎湃看中国｜技术创新引领新能源汽车产...   \n",
       "11                  1097  新潮澎湃看中国｜技术创新引领新能源汽车产业不断升级 新潮澎湃看中国｜技术创新引领新能源汽车产...   \n",
       "12                  1635  Keywords : [jefe de la, los gobiernos y los in...   \n",
       "13                  1635  Sign up Sign in Sign up Sign in Member-only st...   \n",
       "14                  1635  -- Written by Elisa Cabana PhD in Statistics, ...   \n",
       "15                 25512  Keywords : [de la, le paradoxe de la Chine, le...   \n",
       "16                 25512  Ce que les images révèlent Israël-Iran : retou...   \n",
       "17                 25512  Malgré l’avis défavorable de Bercy. Et le tabl...   \n",
       "18                  3409  Keywords : [KI, das Risiko der Auslöschung dur...   \n",
       "19                  3409  Künstliche Intelligenz: KI-Koryphäen von OpenA...   \n",
       "20                  3409  Unterschrieben von denen, die KI selbst entwic...   \n",
       "21                 12140  Keywords : [es un framework que, lo bueno de e...   \n",
       "22                 12140  Algo muy importante para mencionar es que Reac...   \n",
       "23                 12140  Híbrido(Hybrid). Recomendaciones -- 1 Written ...   \n",
       "24                 11384  Keywords : [clean energy tax credits, clean en...   \n",
       "25                 11384  Published Time: 2025-05-22T15:01:12.702Z Skip ...   \n",
       "26                 11384  Sign up here. Read Next Sustainability categor...   \n",
       "27                  3582  Keywords : [Data processing, analysis, the con...   \n",
       "28                  3582  In this post, I will explain the six data anal...   \n",
       "29                  3582  Keeping the line of communication with stakeho...   \n",
       "\n",
       "    summary_length  faithfulness  relevance  coherence  conciseness  \\\n",
       "0             1048             3          4          4            4   \n",
       "1              584             4          4          4            4   \n",
       "2              125             1          1          1            1   \n",
       "3              764             4          4          4            4   \n",
       "4              794             4          4          4            4   \n",
       "5               93             1          1          1            1   \n",
       "6             1329             3          3          2            2   \n",
       "7             5628             3          3          3            2   \n",
       "8             4215             3          3          3            3   \n",
       "9             1162             4          4          4            4   \n",
       "10            1096             4          4          4            4   \n",
       "11            1096             4          4          4            4   \n",
       "12            1334             4          4          4            4   \n",
       "13             705             3          4          4            4   \n",
       "14             241             1          1          2            2   \n",
       "15            1469             3          3          3            3   \n",
       "16            1939             3          3          3            3   \n",
       "17             137             2          2          3            4   \n",
       "18            1052             3          3          4            3   \n",
       "19            1053             3          3          3            3   \n",
       "20             558             3          3          3            3   \n",
       "21            1624             3          3          3            3   \n",
       "22            1459             4          4          4            4   \n",
       "23             278             1          1          1            1   \n",
       "24            1361             4          4          4            4   \n",
       "25            3482             3          2          2            2   \n",
       "26            1068             2          2          3            2   \n",
       "27             615             3          3          3            3   \n",
       "28             330             2          2          2            3   \n",
       "29             223             2          2          2            3   \n",
       "\n",
       "    language_consistency  latency_seconds  \n",
       "0                      1         0.267724  \n",
       "1                      1         0.089262  \n",
       "2                      1         0.010286  \n",
       "3                      1         0.178905  \n",
       "4                      1         0.045569  \n",
       "5                      1         0.009005  \n",
       "6                      1         0.156327  \n",
       "7                      1         0.030783  \n",
       "8                      1         0.008437  \n",
       "9                      1         0.022407  \n",
       "10                     1         0.007156  \n",
       "11                     1         0.002012  \n",
       "12                     1         0.053001  \n",
       "13                     1         0.015036  \n",
       "14                     1         0.003000  \n",
       "15                     1         1.000808  \n",
       "16                     1         0.191011  \n",
       "17                     1         0.015679  \n",
       "18                     1         0.088879  \n",
       "19                     1         0.033827  \n",
       "20                     1         0.004107  \n",
       "21                     1         0.333953  \n",
       "22                     1         0.075141  \n",
       "23                     1         0.015269  \n",
       "24                     1         0.328455  \n",
       "25                     1         0.064889  \n",
       "26                     1         0.022150  \n",
       "27                     1         0.084694  \n",
       "28                     1         0.045365  \n",
       "29                     1         0.004997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores per Summarizer:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>conciseness</th>\n",
       "      <th>language_consistency</th>\n",
       "      <th>latency_seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summarizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fast</th>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.251515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            faithfulness  relevance  coherence  conciseness  \\\n",
       "summarizer                                                    \n",
       "fast                 3.4        3.5        3.5          3.4   \n",
       "summy                3.3        3.3        3.3          3.3   \n",
       "tf-idf               2.0        2.0        2.3          2.4   \n",
       "\n",
       "            language_consistency  latency_seconds  \n",
       "summarizer                                         \n",
       "fast                         1.0         0.251515  \n",
       "summy                        1.0         0.059804  \n",
       "tf-idf                       1.0         0.009494  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores per Language and Summarizer:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>conciseness</th>\n",
       "      <th>language_consistency</th>\n",
       "      <th>latency_seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th>summarizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">arabic</th>\n",
       "      <th>fast</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">chinese</th>\n",
       "      <th>fast</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">english</th>\n",
       "      <th>fast</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">french</th>\n",
       "      <th>fast</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">german</th>\n",
       "      <th>fast</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.039698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">spanish</th>\n",
       "      <th>fast</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summy</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     faithfulness  relevance  coherence  conciseness  \\\n",
       "language summarizer                                                    \n",
       "arabic   fast            3.000000   3.000000   2.000000     2.000000   \n",
       "         summy           3.000000   3.000000   3.000000     2.000000   \n",
       "         tf-idf          3.000000   3.000000   3.000000     3.000000   \n",
       "chinese  fast            4.000000   4.000000   4.000000     4.000000   \n",
       "         summy           4.000000   4.000000   4.000000     4.000000   \n",
       "         tf-idf          4.000000   4.000000   4.000000     4.000000   \n",
       "english  fast            3.333333   3.666667   3.666667     3.666667   \n",
       "         summy           3.000000   2.666667   2.666667     3.000000   \n",
       "         tf-idf          1.666667   1.666667   2.000000     2.000000   \n",
       "french   fast            3.000000   3.000000   3.000000     3.000000   \n",
       "         summy           3.000000   3.000000   3.000000     3.000000   \n",
       "         tf-idf          2.000000   2.000000   3.000000     4.000000   \n",
       "german   fast            3.500000   3.500000   4.000000     3.500000   \n",
       "         summy           3.500000   3.500000   3.500000     3.500000   \n",
       "         tf-idf          2.000000   2.000000   2.000000     2.000000   \n",
       "spanish  fast            3.500000   3.500000   3.500000     3.500000   \n",
       "         summy           3.500000   4.000000   4.000000     4.000000   \n",
       "         tf-idf          1.000000   1.000000   1.500000     1.500000   \n",
       "\n",
       "                     language_consistency  latency_seconds  \n",
       "language summarizer                                         \n",
       "arabic   fast                         1.0         0.156327  \n",
       "         summy                        1.0         0.030783  \n",
       "         tf-idf                       1.0         0.008437  \n",
       "chinese  fast                         1.0         0.022407  \n",
       "         summy                        1.0         0.007156  \n",
       "         tf-idf                       1.0         0.002012  \n",
       "english  fast                         1.0         0.226958  \n",
       "         summy                        1.0         0.066505  \n",
       "         tf-idf                       1.0         0.012478  \n",
       "french   fast                         1.0         1.000808  \n",
       "         summy                        1.0         0.191011  \n",
       "         tf-idf                       1.0         0.015679  \n",
       "german   fast                         1.0         0.133892  \n",
       "         summy                        1.0         0.039698  \n",
       "         tf-idf                       1.0         0.006556  \n",
       "spanish  fast                         1.0         0.193477  \n",
       "         summy                        1.0         0.045089  \n",
       "         tf-idf                       1.0         0.009134  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Summary Length per Summarizer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "summarizer\n",
       "fast      1175.8\n",
       "summy     1707.0\n",
       "tf-idf     803.4\n",
       "Name: summary_length, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nEvaluation Results:\")\n",
    "display(df_results) \n",
    "\n",
    "# %% [markdown]\n",
    "# ### Average Scores per Summarizer\n",
    "\n",
    "# %%\n",
    "# Calculate average scores, ensuring numeric conversion for score columns\n",
    "score_cols = ['faithfulness', 'relevance', 'coherence', 'conciseness', 'language_consistency', 'latency_seconds']\n",
    "for col in score_cols:\n",
    "    df_results[col] = pd.to_numeric(df_results[col], errors='coerce')\n",
    "\n",
    "avg_scores = df_results.groupby('summarizer')[score_cols].mean()\n",
    "print(\"\\nAverage Scores per Summarizer:\")\n",
    "display(avg_scores)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Average Scores per Language\n",
    "\n",
    "# %%\n",
    "avg_scores_lang = df_results.groupby(['language', 'summarizer'])[score_cols].mean()\n",
    "print(\"\\nAverage Scores per Language and Summarizer:\")\n",
    "display(avg_scores_lang)\n",
    "\n",
    "# summary_length per summarizer\n",
    "avg_summary_length = df_results.groupby('summarizer')['summary_length'].mean()\n",
    "print(\"\\nAverage Summary Length per Summarizer:\")\n",
    "display(avg_summary_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'evaluation_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# save results to CSV\u001b[39;00m\n\u001b[32m      2\u001b[39m output_path = \u001b[33m'\u001b[39m\u001b[33mevaluation_results.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\repos\\search-summaries\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\repos\\search-summaries\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\repos\\search-summaries\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\repos\\search-summaries\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\repos\\search-summaries\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'evaluation_results.csv'"
     ]
    }
   ],
   "source": [
    "# save results to CSV\n",
    "output_path = 'evaluation_results.csv'\n",
    "df_results.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
